Part a:
    Task 1:
        - Check if data values are reasonable, such as house prices
          and locations.
        - Some scaling and maximum values are defined without
          explanation, such as income and house value.
        - rooms_per_person has a few very high values outside of the
          normal spread of data.
    Task 2:
        The distribution of values should be roughly evenly split for
        the training and validation data, which is not the case.
    Task 3:
        The code that does data randomization is commented out, so the
        distribution of data will not be even if the data comes pre-
        sorted.
    Task 4:
        def train_model(
            learning_rate,
            steps,
            batch_size,
            training_examples,
            training_targets,
            validation_examples,
            validation_targets):
          """Trains a linear regression model of multiple features.

          In addition to training, this function also prints training progress information,
          as well as a plot of the training and validation loss over time.

          Args:
            learning_rate: A `float`, the learning rate.
            steps: A non-zero `int`, the total number of training steps. A training step
              consists of a forward and backward pass using a single batch.
            batch_size: A non-zero `int`, the batch size.
            training_examples: A `DataFrame` containing one or more columns from
              `california_housing_dataframe` to use as input features for training.
            training_targets: A `DataFrame` containing exactly one column from
              `california_housing_dataframe` to use as target for training.
            validation_examples: A `DataFrame` containing one or more columns from
              `california_housing_dataframe` to use as input features for validation.
            validation_targets: A `DataFrame` containing exactly one column from
              `california_housing_dataframe` to use as target for validation.

          Returns:
            A `LinearRegressor` object trained on the training data.
          """

          periods = 10
          steps_per_period = steps / periods

          # Create a linear regressor object.
          my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
          my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)
          linear_regressor = tf.estimator.LinearRegressor(
              feature_columns=construct_feature_columns(training_examples),
              optimizer=my_optimizer
          )

          # Create input functions.
          training_input_fn = lambda: my_input_fn(
              training_examples,
              training_targets["median_house_value"],
              batch_size=batch_size)
          predict_training_input_fn = lambda: my_input_fn(
              training_examples,
              training_targets["median_house_value"],
              num_epochs=1,
              shuffle=False)
          predict_validation_input_fn = lambda: my_input_fn(
              validation_examples, validation_targets["median_house_value"],
              num_epochs=1,
              shuffle=False)

          # Train the model, but do so inside a loop so that we can periodically assess
          # loss metrics.
          print("Training model...")
          print("RMSE (on training data):")
          training_rmse = []
          validation_rmse = []
          for period in range (0, periods):
            # Train the model, starting from the prior state.
            linear_regressor.train(
                input_fn=training_input_fn,
                steps=steps_per_period,
            )
            # Take a break and compute predictions.
            training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)
            training_predictions = np.array([item['predictions'][0] for item in training_predictions])

            validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)
            validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])


            # Compute training and validation loss.
            training_root_mean_squared_error = math.sqrt(
                metrics.mean_squared_error(training_predictions, training_targets))
            validation_root_mean_squared_error = math.sqrt(
                metrics.mean_squared_error(validation_predictions, validation_targets))
            # Occasionally print the current loss.
            print("  period %02d : %0.2f" % (period, training_root_mean_squared_error))
            # Add the loss metrics from this period to our list.
            training_rmse.append(training_root_mean_squared_error)
            validation_rmse.append(validation_root_mean_squared_error)
          print("Model training finished.")

          # Output a graph of loss metrics over periods.
          plt.ylabel("RMSE")
          plt.xlabel("Periods")
          plt.title("Root Mean Squared Error vs. Periods")
          plt.tight_layout()
          plt.plot(training_rmse, label="training")
          plt.plot(validation_rmse, label="validation")
          plt.legend()

          return linear_regressor
        linear_regressor = train_model(
            learning_rate=0.00003,
            steps=500,
            batch_size=5,
            training_examples=training_examples,
            training_targets=training_targets,
            validation_examples=validation_examples,
            validation_targets=validation_targets)
    Task 5:
        california_housing_test_data = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv", sep=",")

        test_examples = preprocess_features(california_housing_test_data)
        test_targets = preprocess_targets(california_housing_test_data)

        predict_test_input_fn = lambda: my_input_fn(
              test_examples,
              test_targets["median_house_value"],
              num_epochs=1,
              shuffle=False)

        test_predictions = linear_regressor.predict(input_fn=predict_test_input_fn)
        test_predictions = np.array([item['predictions'][0] for item in test_predictions])

        root_mean_squared_error = math.sqrt(
            metrics.mean_squared_error(test_predictions, test_targets))

        print("Final RMSE (on test data): %0.2f" % root_mean_squared_error)
Part b:
    Training data sets are used to train the model to predict house
    values accurately. Validation data sets are used to refine the
    model's accuracy, and are different than the training data sets
    so that the model does not become skewed for one set of data.
    Finally, testing datasets are used to evaluate how well the
    model performs on an entirely new set of data. In this example,
    One data set was split into two parts for the training and
    validation data sets, and a separate set of data was used for
    testing.